import operator
from typing_extensions import TypedDict
from typing import Sequence, List, Annotated,Literal

from pydantic import BaseModel, Field

class BaseMessage(BaseModel):
    '''Define the fundamental type of data for LLM outputs.'''
    content: str
    sender: str

class AgentState(BaseModel):
    '''Define necessary parameters in the iterative pipeline of LLM clients.'''
    messages: Annotated[Sequence[BaseMessage], operator.add] # Sequence of BaseMessage to collect the messages generated by members in the iterative pipeline
    reaction_background: str = Field(default='background') # A string to describe the reaction background
    target_name: str = Literal['Fe/Hf','modifier/SBU','yield'] # Determination of the concerned target
    Fe_pred_flag: bool = Field(default=False) # Determination of whether to concatenate Fe loading data into the train data
    
    #LOO utilities
    train_performance: list = Field(default=[]) # List to record the accuracies on the train set during one iteration (From Rule Generator to Project Manager)
    test_prediction: list = Field(default=[]) # List to record the predictions for the test sample during one iteration
    current_val_performance: float = Field(default=0.0) #  List to record the accuracies on the validation set (generated by 5 fold cross-validation on the train set) during one iteration
    
    # Parameter settings
    output_dir: str = Field(default='instant') # The path of processed directory.
    train_file: str = Field(default='train_set.csv') # The file name of the splitted train set. Yield, name and SMILES of samples are provided in the file.
    test_file: str = Field(default='test_set.csv') # The file name of the splitted train set.
    train_matrix: str = Field(default='train_matrix.csv') # The whole feature matrix of train set.
    test_matrix: str = Field(default='test_matrix.csv') # The whole feature matrix of test set.
    exp_train: str = Field(default='exp_train.csv') # The experimental descriptors of the splitted train set.
    exp_test: str = Field(default='exp_test.csv') # The experimental descriptors of the splitted test set.
    selected_train_matrix: str = Field(default='selected_train_mtx.csv') # Selected features by RFECV for the train set.
    selected_test_matrix: str = Field(default='selected_test_mtx.csv') # Selected features by RFECV for the test set.
    current_matrix: str = Field(default='current_matrix.txt') # The matrix for train and test set for the current iteration.
    Tran_model: str = Literal['ETC', 'RFC'] # ExtraTreesClassifier or randomForestClassifier. The classification model used in the Traditional Calculator.
    # Arguments for LLM client
    GPT_model: str = Literal['gpt-4o-2024-08-06', 'gpt-4o-mini-2024-07-18', 'o1-preview-2024-09-12', 'deepseek-r1']
    GPT_temperature: float = Field(default=1.0)
    GPT_seed: int = Field(default=42) # Random seed for the LLM clients 
    seed: int = Field(default=42) # Random seed for any other non-LLM parts.
    
    #Logging parameters
    generate_count: int = Field(default=0) # The historical number of rule generations.
    current_gen_count: int = Field(default=0) # The number of rule generations in the current iteration
    current_mtx_gen: int = Field(default=0) # The number of matrix generations in the current iteration
    train_len: int = Field(default=0) # The number of samples in the train set.
    whole_len: int = Field(default=0) # The number of samples in train and test set.
    completion_tokens: int = Field(default=0) # The number of tokens in LLM completions.
    prompt_tokens: int = Field(default=0) # The number of tokens in LLM prompts.
    
class OverallState(TypedDict):
    '''A simplified version of AgentState for dataset splitting.'''
    output_folder: str
    GPT_model: str = Literal['gpt-4o-2024-08-06', 'gpt-4o-mini-2024-07-18', 'o1-preview-2024-09-12', 'deepseek-r1']
    target_name: str = Literal['Fe/Hf','modifier/SBU','yield']
    test_true: Annotated[list, operator.add]
    test_pred: Annotated[list, operator.add]
    loo_log: Annotated[list,operator.add]
    test_accuracy: float