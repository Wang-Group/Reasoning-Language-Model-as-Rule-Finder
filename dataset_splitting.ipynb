{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting dataset for iterative GPT pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent.state import OverallState\n",
    "\n",
    "target_name = \"yield\"\n",
    "Fe_loading_flag = False\n",
    "INPUT = {\n",
    "  \"target_name\": target_name,\n",
    "}\n",
    "state = OverallState(INPUT)\n",
    "print(state)\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "import pkg_resources\n",
    "\n",
    "# GPT_model = state['GPT_model']\n",
    "target_name = state['target_name']\n",
    "# Reading the dataset\n",
    "dataset_path = pkg_resources.resource_filename('agent.data', 'data.csv')\n",
    "data = pd.read_csv(dataset_path)\n",
    "name = pd.read_csv(pkg_resources.resource_filename('agent.data', 'name.csv'))['name']\n",
    "# Check and create appropriate `append_name` based on `target_name`\n",
    "if target_name == 'Fe/Hf':\n",
    "    append_name = 'Fe_Hf'\n",
    "elif target_name == 'modifier/SBU':\n",
    "    append_name = 'modi_SBU'\n",
    "elif target_name == 'yield':\n",
    "    append_name = 'yield'\n",
    "else:\n",
    "    raise ValueError(f\"Invalid target_name: {target_name}. Must be 'Fe/Hf', 'modifier/SBU' or 'yield'.\")\n",
    "\n",
    "# Initialize the output folder\n",
    "date_index = 'yield_o1_test'\n",
    "output_folder = append_name + '_' + date_index\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "\n",
    "# Load SMILES, name anc experimental descriptors for samples\n",
    "SMILES = data['SMILES']\n",
    "NAME = name\n",
    "Fe_loading = data['Fe_loading']\n",
    "modifier_SBU = data['modifier/SBU']\n",
    "Fe_Hf = data['Fe/Hf']\n",
    "target_values = data[target_name]\n",
    "high_or_low_loading = data[target_name] > data[target_name].median()\n",
    "\n",
    "# Generate dataset containing necessary columns\n",
    "dataset = pd.DataFrame({\n",
    "    target_name:target_values,\n",
    "    'name': NAME,\n",
    "    'SMILES': SMILES,\n",
    "    f'{target_name}_high_or_low_value': high_or_low_loading\n",
    "})\n",
    "\n",
    "exp_dataset = pd.DataFrame({\n",
    "    'Fe_loading': Fe_loading,\n",
    "    'modifier/SBU': modifier_SBU,\n",
    "    'Fe/Hf': Fe_Hf\n",
    "})\n",
    "\n",
    "# Add Fe loading values to the dataset if commanded\n",
    "if Fe_loading_flag:\n",
    "    Fe_loading_df = pd.read_csv(pkg_resources.resource_filename('agent.data', 'data_yield.csv'))[['yield_high_or_low_pred_by_Fe_loading']]\n",
    "    Fe_loading_data = pd.read_csv(pkg_resources.resource_filename('agent.data', 'data.csv'))[['Fe_loading']]\n",
    "    Fe_loading_df = pd.concat([Fe_loading_df, Fe_loading_data],axis=1)\n",
    "    \n",
    "# Read the reference values for rule metrics (support, confidence, lift and leverage) and traditional metrics (accuracies and SHAP values).\n",
    "rule_hist_path = pkg_resources.resource_filename('agent.data', f\"pre_rule_metric_{append_name}.txt\")\n",
    "with open(rule_hist_path,'r') as f:\n",
    "    content = f.read()\n",
    "content = '< Previous Rule Metrics for Reference: >\\n'+ content + '\\n< Rule Metrics During the Iteration of This Program: >\\n'\n",
    "trad_hist_path = pkg_resources.resource_filename('agent.data', f\"pre_trad_metric_{append_name}.txt\")\n",
    "with open(trad_hist_path,'r') as f:\n",
    "    content1 = f.read()\n",
    "content1 = '< Previous Accuracy for Reference: >\\n'+ content1 + '\\n< Accuracy and SHAP During the Iteration of This Program: >\\n'\n",
    "# Leave-One-Out cross-validation\n",
    "loo = LeaveOneOut()\n",
    "index = 1\n",
    "\n",
    "# Generate LOO splitted datasets\n",
    "for train_index, test_index in loo.split(dataset):\n",
    "    if index == 36:\n",
    "        # Get the train and test sets\n",
    "        train_set = dataset.iloc[train_index]\n",
    "        test_set = dataset.iloc[test_index]\n",
    "        \n",
    "        exp_train = exp_dataset.iloc[train_index]\n",
    "        exp_test = exp_dataset.iloc[test_index]\n",
    "        \n",
    "        \n",
    "        Fe_loading_pred_train = Fe_loading_df.iloc[train_index]\n",
    "        Fe_loading_pred_test = Fe_loading_df.iloc[test_index]\n",
    "        \n",
    "        # Create a new directory for each split\n",
    "        split_folder = os.path.join(output_folder, str(index))\n",
    "        os.makedirs(split_folder, exist_ok=True)\n",
    "        \n",
    "        # Save the train and test sets\n",
    "        train_set.to_csv(os.path.join(split_folder, 'train_set.csv'), index=False)\n",
    "        test_set.to_csv(os.path.join(split_folder, 'test_set.csv'), index=False)\n",
    "        \n",
    "        exp_train.to_csv(os.path.join(split_folder, 'exp_train.csv'), index=False)\n",
    "        exp_test.to_csv(os.path.join(split_folder, 'exp_test.csv'), index=False)\n",
    "        \n",
    "        Fe_loading_pred_train.to_csv(os.path.join(split_folder, 'Fe_pred_train.csv'), index=False)\n",
    "        Fe_loading_pred_test.to_csv(os.path.join(split_folder, 'Fe_pred_test.csv'), index=False)\n",
    "        \n",
    "        with open(os.path.join(split_folder,'rule_metric_log.txt'),'w') as f1:\n",
    "            f1.write(content)\n",
    "        \n",
    "        with open(os.path.join(split_folder,'trad_metric_log.txt'),'w') as f1:\n",
    "            f1.write(content1)\n",
    "        \n",
    "    index += 1\n",
    "print(f\"Data splits have been saved in the '{output_folder}' directory.\")\n",
    "# print('This inputs containing experimental data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
