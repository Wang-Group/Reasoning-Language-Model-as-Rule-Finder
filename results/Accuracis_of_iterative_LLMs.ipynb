{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOO accuracy of 4o (no Code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOO accuracy of 4o (no Code)\n",
      "Test True Values: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1]\n",
      "Test Pred Values: [1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0]\n",
      "Test Accuracy: 0.3333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "with open(\"LLM_pipeline_outputs/yield_nocode_4o/loo_out_log.txt\",'r') as f:\n",
    "    data = f.read()\n",
    "# print(data)\n",
    "\n",
    "# Extract the Test True and Test Pred values using regex\n",
    "test_true_values = re.findall(r\"Test True:([a-zA-Z]+),Test Pred:\", data)\n",
    "test_pred_values = re.findall(r\"Test Pred: ([a-zA-Z]+)\", data)\n",
    "\n",
    "# Convert True/False strings to int (1 for True, 0 for False)\n",
    "test_true_values = [1 if val == \"True\" else 0 for val in test_true_values]\n",
    "test_pred_values = [1 if val == \"True\" else 0 for val in test_pred_values]\n",
    "\n",
    "# Calculate test accuracy\n",
    "correct_predictions = sum(t == p for t, p in zip(test_true_values, test_pred_values))\n",
    "accuracy = correct_predictions / len(test_true_values)\n",
    "\n",
    "print('LOO accuracy of 4o (no Code)')\n",
    "print(f\"Test True Values: {test_true_values}\")\n",
    "print(f\"Test Pred Values: {test_pred_values}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOO accuracy of 4o (Code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOO accuracy of 4o (Code)\n",
      "Test True Values: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1]\n",
      "Test Pred Values: [0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1]\n",
      "Test Accuracy: 0.2222\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "with open(\"LLM_pipeline_outputs/yield_coded_4o/loo_out_log.txt\",'r') as f:\n",
    "    data = f.read()\n",
    "# print(data)\n",
    "\n",
    "# Extract the Test True and Test Pred values using regex\n",
    "test_true_values = re.findall(r\"Test True:([a-zA-Z]+),Test Pred:\", data)\n",
    "test_pred_values = re.findall(r\"Test Pred: ([a-zA-Z]+)\", data)\n",
    "\n",
    "# Convert True/False strings to int (1 for True, 0 for False)\n",
    "test_true_values = [1 if val == \"True\" else 0 for val in test_true_values]\n",
    "test_pred_values = [1 if val == \"True\" else 0 for val in test_pred_values]\n",
    "\n",
    "# Calculate test accuracy\n",
    "correct_predictions = sum(t == p for t, p in zip(test_true_values, test_pred_values))\n",
    "accuracy = correct_predictions / len(test_true_values)\n",
    "\n",
    "print('LOO accuracy of 4o (Code)')\n",
    "print(f\"Test True Values: {test_true_values}\")\n",
    "print(f\"Test Pred Values: {test_pred_values}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOO accuracy of o1 (no Code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOO accuracy of o1 (no Code)\n",
      "Test True Values: [1, 1, 1, 1, 1]\n",
      "Test Pred Values: [1, 0, 1, 0, 0]\n",
      "Test Accuracy: 0.4000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "with open(\"LLM_pipeline_outputs/yield_nocode_o1/loo_out_log.txt\",'r') as f:\n",
    "    data = f.read()\n",
    "# print(data)\n",
    "\n",
    "# Extract the Test True and Test Pred values using regex\n",
    "test_true_values = re.findall(r\"Test True:([a-zA-Z]+),Test Pred:\", data)\n",
    "test_pred_values = re.findall(r\"Test Pred: ([a-zA-Z]+)\", data)\n",
    "\n",
    "# Convert True/False strings to int (1 for True, 0 for False)\n",
    "test_true_values = [1 if val == \"True\" else 0 for val in test_true_values]\n",
    "test_pred_values = [1 if val == \"True\" else 0 for val in test_pred_values]\n",
    "\n",
    "# Calculate test accuracy\n",
    "correct_predictions = sum(t == p for t, p in zip(test_true_values, test_pred_values))\n",
    "accuracy = correct_predictions / len(test_true_values)\n",
    "\n",
    "print('LOO accuracy of o1 (no Code)')\n",
    "print(f\"Test True Values: {test_true_values}\")\n",
    "print(f\"Test Pred Values: {test_pred_values}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOO accuracy of o1 (Code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOO accuracy of o1 (Code)\n",
      "Test True Values: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Test Pred Values: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0]\n",
      "Test Accuracy: 0.6111\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "with open(\"LLM_pipeline_outputs/yield_o1/loo_out_log.txt\",'r') as f:\n",
    "    data = f.read()\n",
    "# print(data)\n",
    "\n",
    "# Extract the Test True and Test Pred values using regex\n",
    "test_true_values = re.findall(r\"Test True:([a-zA-Z]+),Test Pred:\", data)\n",
    "test_pred_values = re.findall(r\"Test Pred: ([a-zA-Z]+)\", data)\n",
    "\n",
    "# Convert True/False strings to int (1 for True, 0 for False)\n",
    "test_true_values = [1 if val == \"True\" else 0 for val in test_true_values]\n",
    "test_pred_values = [1 if val == \"True\" else 0 for val in test_pred_values]\n",
    "\n",
    "# Calculate test accuracy\n",
    "correct_predictions = sum(t == p for t, p in zip(test_true_values, test_pred_values))\n",
    "accuracy = correct_predictions / len(test_true_values)\n",
    "\n",
    "print('LOO accuracy of o1 (Code)')\n",
    "print(f\"Test True Values: {test_true_values}\")\n",
    "print(f\"Test Pred Values: {test_pred_values}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
